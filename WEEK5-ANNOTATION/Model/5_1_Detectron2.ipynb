{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# I. Install Detectron2"
      ],
      "metadata": {
        "id": "1vqMuiqjsAGp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2TovH-ojp1hT"
      },
      "outputs": [],
      "source": [
        "!python -m pip install pyyaml==5.1\n",
        "!pip install cython pyyaml==5.1\n",
        "!pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n",
        "# Detectron2 has not released pre-built binaries for the latest pytorch (https://github.com/facebookresearch/detectron2/issues/4053)\n",
        "# so we install from source instead. This takes a few minutes.\n",
        "!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Check Detectron2 Version"
      ],
      "metadata": {
        "id": "jyx7nUmQsXWL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, detectron2\n",
        "!nvcc --version\n",
        "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
        "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
        "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
        "print(\"detectron2:\", detectron2.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlH3GYZXsWaP",
        "outputId": "1bca653c-3a8f-4407-bcdd-486d6711d946"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
            "Cuda compilation tools, release 11.8, V11.8.89\n",
            "Build cuda_11.8.r11.8/compiler.31833905_0\n",
            "torch:  2.1 ; cuda:  cu118\n",
            "detectron2: 0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Setup: Import Library"
      ],
      "metadata": {
        "id": "gokPlCWTs7Zm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# You may need to restart your runtime prior to this, to let your installation take effect\n",
        "# Some basic setup\n",
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "from google.colab.patches import cv2_imshow\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog\n",
        "from detectron2.data.catalog import DatasetCatalog"
      ],
      "metadata": {
        "id": "hUoSti8ls2PA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section, we show how to train an existing detectron2 model on a custom dataset in COCO format.\n",
        "\n",
        "## 2.1 Prepare the dataset"
      ],
      "metadata": {
        "id": "yuZt_s5suXBP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "_o_GZJTOtCkf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/drive/MyDrive/colab_dataset/image_train_dark.zip\""
      ],
      "metadata": {
        "id": "ulPobWhYtUYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Register the custom dataset to Detectron2, following the detectron2 custom dataset tutorial. Here, the dataset is in COCO format, therefore we register into Detectron2's standard format. User should write such a function when using a dataset in custom format. See the tutorial for more details."
      ],
      "metadata": {
        "id": "I-wyPKksuhd9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.data.datasets import register_coco_instances\n",
        "from detectron2.data import get_detection_dataset_dicts\n",
        "from detectron2.data.datasets import builtin_meta"
      ],
      "metadata": {
        "id": "0vxPKocNujFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for d in [\"train\", \"val\"]:\n",
        "    # register_coco_instances(f\"orchid_{d}\", {}, f\"/content/leaves_core/annotations/{d}.json\", f\"/content/leaves_core/{d}\")\n",
        "    register_coco_instances(f\"dark_{d}\", {}, f\"/content/dark/annotations/{d}.json\", f\"/content/dark/{d}\")\n",
        "MetadataCatalog.get(\"dark_train\").set(thing_classes = ['bud','core']).set(thing_dataset_id_to_contiguous_id={1: 0,2: 1})\n",
        "MetadataCatalog.get(\"dark_val\").set(thing_classes = ['bud','core']).set(thing_dataset_id_to_contiguous_id={1: 0,2: 1})"
      ],
      "metadata": {
        "id": "_Ubu_YWfuy0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To verify the data loading is correct, let's visualize the annotations of a randomly selected sample in the training set:"
      ],
      "metadata": {
        "id": "Q-8aqIHAvWY6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.utils.visualizer import  Visualizer\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.utils.visualizer import ColorMode\n",
        "import os, json, cv2, random\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "oaLUO5wMvWHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_sample(dataset_name,n=1):\n",
        "  dataset_custom = DatasetCatalog.get(dataset_name)\n",
        "  dataset_custom_mega = MetadataCatalog.get(dataset_name)\n",
        "  for s in random.sample(dataset_custom,n):\n",
        "    im = cv2.imread(s[\"file_name\"])\n",
        "    v = Visualizer(im[:,:,::-1],metadata=dataset_custom_mega, scale = 0.5)\n",
        "    v = v.draw_dataset_dict(s)\n",
        "    plt.figure(figsize=(15,20))\n",
        "    plt.imshow(v.get_image())\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "pCQK0mmyvcQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_sample(dataset_name=\"dark_val\",n=1)"
      ],
      "metadata": {
        "id": "_5x8AGuXvsmP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Training"
      ],
      "metadata": {
        "id": "rXpSK1akwv_Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.data import build_detection_train_loader\n",
        "import detectron2.utils.comm as comm\n",
        "import os"
      ],
      "metadata": {
        "id": "asHkJ4wTvu4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "cfg.DATASETS.TRAIN = (\"dark_train\",)\n",
        "cfg.DATASETS.TEST = ()\n",
        "cfg.DATALOADER.NUM_WORKERS = 2 #@param\n",
        "cfg.DATALOADER.SAMPLER_TRAIN = \"RepeatFactorTrainingSampler\"\n",
        "cfg.DATALOADER.REPEAT_THRESHOLD = 0.3\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
        "cfg.SOLVER.IMS_PER_BATCH =  8 #@param\n",
        "cfg.SOLVER.BASE_LR = 0.0025 #@param # pick a good LR\n",
        "cfg.SOLVER.MAX_ITER = 1000 #@param    # 300 iterations seems good enough for 100 frames dataset; you will need to train longer for a practical dataset\n",
        "cfg.SOLVER.CHECKPOINT_PERIOD = 1000 #@param\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128 #@param   # faster, and good enough for this toy dataset (default: 512)\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 2 #@param  #  (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "trainer = DefaultTrainer(cfg)\n",
        "trainer.resume_or_load(resume=False)"
      ],
      "metadata": {
        "id": "Crlpqm82x2RL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Look at training curves in tensorboard:\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir output"
      ],
      "metadata": {
        "id": "kwqXhAMhzLGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "2SbijMF4zLk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Inference & evaluation using the trained model\n",
        "Now, let's run inference with the trained model on the validation dataset. First, let's create a predictor using the model we just trained:"
      ],
      "metadata": {
        "id": "UyxVxqOYze7F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1 Inference"
      ],
      "metadata": {
        "id": "ZzAL5gf4zxls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inference should use the config with parameters that are used in training\n",
        "# cfg now already contains everything we've set previously.\n",
        "# We simply update the weights with the newly trained ones to perform inference:\n",
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
        "# set a custom testing threshold\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.15   #@param {type: \"slider\", min:0.0, max:1.0, step: 0.01}\n",
        "predictor = DefaultPredictor(cfg)"
      ],
      "metadata": {
        "id": "nYVk4z56zg9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import random\n",
        "from detectron2.utils.visualizer import Visualizer"
      ],
      "metadata": {
        "id": "THMh5LQxz5ji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = glob.glob(\"/content/dark/val/*.jpg\")"
      ],
      "metadata": {
        "id": "XzYEbzDf1Hcq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def on_image(image_path,predictor):\n",
        "  dataset_custom_mega = MetadataCatalog.get(\"dark_train\")\n",
        "  im = cv2.imread(image_path)\n",
        "  outputs = predictor(im)\n",
        "  # v = Visualizer(im[:,:,::-1], metadata = {},scale = 0.5, instance_mode = ColorMode.SEGMENTATION)\n",
        "  v = Visualizer(im[:,:,::-1], metadata = dataset_custom_mega,scale = 0.5,)\n",
        "  v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "  predicted = outputs[\"instances\"].pred_classes.to(\"cpu\")\n",
        "  print(\"classes\",predicted)\n",
        "  plt.figure(figsize = (14,10))\n",
        "  plt.imshow(v.get_image())\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "rtAx6ZLC1Jt7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for image in random.sample(image_path,10):\n",
        "  im = cv2.imread(image)\n",
        "  cv2_imshow(im)\n",
        "  on_image(image,predictor)"
      ],
      "metadata": {
        "id": "_bEQQXkZ1ONm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2 Evaluation: AP (Average Precision)\n",
        "\n",
        "A more robust way to evaluate the model is to use a metric called Average Precision (AP) already implemented in the detectron2 package. If you want more precision on what the AP is, you can take a look [here](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.average_precision_score.html#sklearn.metrics.average_precision_score) and [here](https://en.wikipedia.org/w/index.php?title=Information_retrieval&oldid=793358396#Average_precision)."
      ],
      "metadata": {
        "id": "WtvxwI4p1gQS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "from detectron2.data import build_detection_test_loader"
      ],
      "metadata": {
        "id": "LFNHPc1E1o40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator = COCOEvaluator(\"dark_valid\", cfg, False, output_dir=\"/content/eval_output/\")\n",
        "val_loader = build_detection_test_loader(cfg, \"dark_valid\")\n",
        "print(inference_on_dataset(predictor.model, val_loader, evaluator))\n",
        "# another equivalent way to evaluate the model is to use `trainer.test`"
      ],
      "metadata": {
        "id": "Md-Pgm0v11KQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}